{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564bde17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`~sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "\n",
      "|details-sta\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# for this lecture, we will restrict our attention to just 4 different newsgroups:\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "# load the dataset\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# print some information on it\n",
    "print(twenty_train.DESCR[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1ca005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The set of targets in this dataset are the newgroup topics:\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb404b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n"
     ]
    }
   ],
   "source": [
    "# We have about 2k data point in total\n",
    "print(len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048d5f2",
   "metadata": {},
   "source": [
    "#### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db54a256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize the training set\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "X_train = count_vect.fit_transform(twenty_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c35e162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index for the word \"church\":  8609\n",
      "Index for the word \"computer\":  9338\n"
     ]
    }
   ],
   "source": [
    "# The CounterVectorizer class records the index j associated \n",
    "print('Index for the word \"church\": ', count_vect.vocabulary_.get(u'church'))\n",
    "print('Index for the word \"computer\": ', count_vect.vocabulary_.get(u'computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c1d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: s0612596@let.rug.nl (M.M. Zwart)\n",
      "Subject: catholic church poland\n",
      "Organization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\n",
      "Lines: 10\n",
      "\n",
      "Hello,\n",
      "\n",
      "I'm writing a paper on the role of the catholic church in Poland after 1989. \n",
      "Can anyone tell me more about this, or fill me in on recent books/articles(\n",
      "in english, german or french). Most important for me is the role of the \n",
      "church concerning the abortion-law, religious education at schools,\n",
      "birth-control and the relation church-state(government). Thanx,\n",
      "\n",
      "                                                 Masja,\n",
      "\"M.M.Zwart\"<s0612596@let.rug.nl>\n",
      "\n",
      "------------------------------------------------------------\n",
      "Value at the index for the word \"church\":  1\n",
      "Value at the index for the word \"computer\":  0\n",
      "Value at the index for the word \"doctor\":  0\n",
      "Value at the index for the word \"important\":  1\n"
     ]
    }
   ],
   "source": [
    "# We can examine if any of these words are present in our previous datapoint\n",
    "print(twenty_train.data[3])\n",
    "\n",
    "# let's see if it contains these two words?\n",
    "print('---'*20)\n",
    "print('Value at the index for the word \"church\": ', X_train[3, count_vect.vocabulary_.get(u'church')])\n",
    "print('Value at the index for the word \"computer\": ', X_train[3, count_vect.vocabulary_.get(u'computer')])\n",
    "print('Value at the index for the word \"doctor\": ', X_train[3, count_vect.vocabulary_.get(u'doctor')])\n",
    "print('Value at the index for the word \"important\": ', X_train[3, count_vect.vocabulary_.get(u'important')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b6eb9",
   "metadata": {},
   "source": [
    "#### Classification Using BoW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b47df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       143156     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.12887D+03    |proj g|=  2.12500D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     38     43      1     0     0   9.100D-05   1.095D-02\n",
      "  F =   1.0948389157689916E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100000.0, multi_class=&#x27;multinomial&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100000.0, multi_class=&#x27;multinomial&#x27;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100000.0, multi_class='multinomial', verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance of Softmax and fit the data.\n",
    "logreg = LogisticRegression(C=1e5, multi_class='multinomial', verbose=True)\n",
    "logreg.fit(X_train, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1319bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "\n",
    "X_new = count_vect.transform(docs_new)\n",
    "predicted = logreg.predict(X_new)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1c4e4",
   "metadata": {},
   "source": [
    "#### We will learn a good set of parameters for a Bernoulli Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54889d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize the training set\n",
    "count_vect = CountVectorizer(binary=True, max_features=1000)\n",
    "y_train = twenty_train.target\n",
    "X_train = count_vect.fit_transform(twenty_train.data).toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c727f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21267169 0.25875055 0.26318121 0.26539654]\n"
     ]
    }
   ],
   "source": [
    "#Let's compute the maximum likelihood model parameters on our dataset.\n",
    "# we can implement these formulas over the Iris dataset\n",
    "n = X_train.shape[0] # size of the dataset\n",
    "d = X_train.shape[1] # number of features in our dataset\n",
    "K = 4 # number of clases\n",
    "\n",
    "# these are the shapes of the parameters\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])\n",
    "\n",
    "# we now compute the parameters\n",
    "for k in range(K):\n",
    "    X_k = X_train[y_train == k]\n",
    "    psis[k] = np.mean(X_k, axis=0)\n",
    "    phis[k] = X_k.shape[0] / float(n)\n",
    "\n",
    "# print out the class proportions\n",
    "print(phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00be94ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 0 3 3 3 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Using Naive Bayes\n",
    "# we can implement this in numpy\n",
    "def nb_predictions(x, psis, phis):\n",
    "    \"\"\"This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "    \"\"\"\n",
    "    # adjust shapes\n",
    "    n, d = x.shape\n",
    "    x = np.reshape(x, (1, n, d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14)\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape([K,1])\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])\n",
    "\n",
    "idx, logpyx = nb_predictions(X_train, psis, phis)\n",
    "print(idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77429e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692955250332299"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acuracy\n",
    "(idx==y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9ce37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['OpenGL on the GPU is fast']\n",
    "\n",
    "X_new = count_vect.transform(docs_new).toarray()\n",
    "predicted, logpyx_new = nb_predictions(X_new, psis, phis)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5698090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
